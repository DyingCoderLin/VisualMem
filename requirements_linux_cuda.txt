accelerate==1.12.0
annotated-doc==0.0.4
annotated-types==0.7.0
anyio==4.12.0
certifi==2025.10.5
charset-normalizer==3.4.4
click==8.3.1
colorlog==6.10.1
dateparser==1.2.2
deprecation==2.1.0
einops==0.8.1
fastapi==0.124.4
filelock==3.19.1
# flash_attn @ https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.3/flash_attn-2.8.3+cu12torch2.8cxx11abiTRUE-cp312-cp312-linux_x86_64.whl#sha256=f25da18657a87fc83dc1bfb8b7751b82246e9db355510226b674fd437c34b5fb
fsspec==2025.9.0
h11==0.16.0
hf-xet==1.2.0
huggingface-hub==0.36.0
idna==3.11
Jinja2==3.1.6
joblib==1.5.2
lance-namespace==0.0.20
lance-namespace-urllib3-client==0.0.20
lancedb==0.25.2
MarkupSafe==3.0.3
mpmath==1.3.0
networkx==3.2.1
ninja==1.13.0
numpy==2.0.2
# nvidia-cublas-cu12==12.8.4.1
# nvidia-cuda-cupti-cu12==12.8.90
# nvidia-cuda-nvrtc-cu12==12.8.93
# nvidia-cuda-runtime-cu12==12.8.90
# nvidia-cudnn-cu12==9.10.2.21
# nvidia-cufft-cu12==11.3.3.83
# nvidia-cufile-cu12==1.13.1.3
# nvidia-curand-cu12==10.3.9.90
# nvidia-cusolver-cu12==11.7.3.90
# nvidia-cusparse-cu12==12.5.8.93
# nvidia-cusparselt-cu12==0.7.1
# nvidia-ml-py==13.580.82
# nvidia-nccl-cu12==2.27.3
# nvidia-nvjitlink-cu12==12.8.93
# nvidia-nvshmem-cu12==3.3.20
# nvidia-nvtx-cu12==12.8.90
# nvitop==1.6.1
overrides==7.7.0
packaging==25.0
pandas==2.3.3
pillow==11.3.0
protobuf==6.33.2
psutil==7.1.3
pyarrow==21.0.0
pydantic==2.12.3
pydantic_core==2.41.4
pylance==0.38.2
PySide6==6.10.0
PySide6_Addons==6.10.0
PySide6_Essentials==6.10.0
pytesseract==0.3.13
python-dateutil==2.9.0.post0
python-dotenv==1.2.1
pytz==2025.2
PyYAML==6.0.3
regex==2025.10.23
requests==2.32.5
safetensors==0.6.2
scikit-learn==1.6.1
scipy==1.13.1
sentence-transformers==5.1.2
sentencepiece==0.2.1
setuptools==80.9.0
shiboken6==6.10.0
six==1.17.0
starlette==0.50.0
sympy==1.14.0
threadpoolctl==3.6.0
tokenizers==0.22.1
torch==2.8.0
torchvision==0.23.0
tqdm==4.67.1
transformers==4.57.3
# triton==3.4.0
typing-inspection==0.4.2
typing_extensions==4.15.0
tzdata==2025.2
tzlocal==5.3.1
urllib3==2.5.0
uvicorn==0.38.0
wheel==0.45.1
